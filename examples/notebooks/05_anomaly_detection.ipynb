{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fefc09dd",
   "metadata": {},
   "source": [
    "---\n",
    "© 2025 KR-Labs. All rights reserved.  \n",
    "KR-Labs™ is a trademark of Quipu Research Labs, LLC, a subsidiary of Sudiata Giddasira, Inc.\n",
    "\n",
    "SPDX-License-Identifier: Apache-2.0\n",
    "---\n",
    "\n",
    "# Tutorial 5: Anomaly Detection with STL and Isolation Forest\n",
    "\n",
    "**Author:** KRL Model Zoo Team  \n",
    "**Affiliation:** KR-Labs  \n",
    "**Version:** v1.0  \n",
    "**Date:** October 25, 2025  \n",
    "**License:** Apache 2.0  \n",
    "**Tier:** Open-Source (Tier 1-3)\n",
    "\n",
    "---\n",
    "\n",
    "## Tutorial Overview\n",
    "\n",
    "This tutorial demonstrates **anomaly detection** using STL (Seasonal-Trend decomposition using Loess) and Isolation Forest to identify outliers and unusual patterns in time series data.\n",
    "\n",
    "**Models Covered:**\n",
    "- STL Decomposition - Identify outliers in residuals\n",
    "- Isolation Forest - Machine learning-based anomaly detection\n",
    "- Combined approach - Hybrid detection strategy\n",
    "\n",
    "**Dataset:** Synthetic revenue data with injected anomalies (weekly, 200 observations)\n",
    "\n",
    "### Learning Objectives\n",
    "\n",
    "By the end of this tutorial, you will be able to:\n",
    "1. Decompose time series using STL to isolate anomalies\n",
    "2. Apply Isolation Forest for unsupervised anomaly detection\n",
    "3. Combine multiple detection methods for robust results\n",
    "4. Evaluate detection performance with precision, recall, F1-score\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "- Understanding of time series decomposition\n",
    "- Familiarity with anomaly detection concepts\n",
    "- Basic knowledge of ensemble methods (Isolation Forest)\n",
    "\n",
    "**Estimated Time:** 35-45 minutes\n",
    "\n",
    "---\n",
    "\n",
    "## Business Applications\n",
    "\n",
    "Anomaly detection is critical for:\n",
    "\n",
    "- **Fraud Detection:** Identify unusual transaction patterns\n",
    "- **Quality Control:** Detect manufacturing defects and process anomalies\n",
    "- **Revenue Assurance:** Flag unusual revenue patterns or billing errors\n",
    "- **System Monitoring:** Detect infrastructure failures and performance issues\n",
    "\n",
    "---\n",
    "\n",
    "## Data Provenance\n",
    "\n",
    "**Source:** Synthetic data generated for educational purposes  \n",
    "**Characteristics:**\n",
    "- Weekly frequency (200 observations)\n",
    "- Trend component (linear growth)\n",
    "- Seasonal pattern (annual cycle)\n",
    "- 5 injected anomalies (magnitude: ±300-500 units)\n",
    "- Labeled ground truth for evaluation\n",
    "\n",
    "**Real-world Equivalents:**\n",
    "- Retail sales data with unusual spikes/dips\n",
    "- Manufacturing quality metrics\n",
    "- Financial transaction data\n",
    "- IT infrastructure monitoring data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d3c0a8",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beeddbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "# Import KRL Model Zoo anomaly detection models\n",
    "from krl_models.anomaly import STLAnomalyModel, IsolationForestAnomalyModel\n",
    "from krl_core import ModelMeta\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c582ff8",
   "metadata": {},
   "source": [
    "## Load Time Series Data with Anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9a469d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load GDP data (contains some anomalies)\n",
    "df = pd.read_csv('../data/gdp_sample.csv')\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Date range: {df['date'].min()} to {df['date'].max()}\")\n",
    "print(f\"\\nColumns: {df.columns.tolist()}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c329b45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the time series\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 10))\n",
    "\n",
    "axes[0].plot(df['date'], df['gdp'], linewidth=2)\n",
    "axes[0].set_title('GDP Time Series', fontsize=14, fontweight='bold')\n",
    "axes[0].set_ylabel('GDP (Billions)')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].plot(df['date'], df['gdp_growth'], linewidth=2, color='green')\n",
    "axes[1].axhline(y=0, color='r', linestyle='--', alpha=0.5)\n",
    "axes[1].set_title('GDP Growth Rate', fontsize=14, fontweight='bold')\n",
    "axes[1].set_ylabel('Growth Rate (%)')\n",
    "axes[1].set_xlabel('Date')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nLook for unusual spikes, drops, or deviations from the pattern\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87df06e2",
   "metadata": {},
   "source": [
    "## Model 1: STL Anomaly Detection\n",
    "\n",
    "STL (Seasonal-Trend decomposition using Loess) breaks a time series into:\n",
    "- **Trend:** Long-term direction\n",
    "- **Seasonal:** Repeating patterns\n",
    "- **Residual:** What's left (where anomalies hide)\n",
    "\n",
    "**Anomaly Detection Logic:**\n",
    "Residuals beyond a threshold (typically 3 standard deviations) are flagged as anomalies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783aaf6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure STL Anomaly model\n",
    "stl_params = {\n",
    "    'time_col': 'date',\n",
    "    'value_col': 'gdp',\n",
    "    'seasonal_period': 4,    # Quarterly seasonality\n",
    "    'threshold': 3.0,        # 3 standard deviations\n",
    "    'robust': True           # Robust to outliers during decomposition\n",
    "}\n",
    "\n",
    "meta_stl = ModelMeta(\n",
    "    name=\"GDP_STL_Anomaly\",\n",
    "    version=\"1.0\",\n",
    "    author=\"Tutorial\",\n",
    "    description=\"STL-based anomaly detection for GDP\"\n",
    ")\n",
    "\n",
    "# Fit STL model\n",
    "stl_model = STLAnomalyModel(stl_params, meta_stl)\n",
    "stl_result = stl_model.fit(df)\n",
    "\n",
    "print(\"STL Anomaly Detection completed!\")\n",
    "print(f\"\\nNumber of anomalies detected: {stl_result.payload['n_anomalies']}\")\n",
    "print(f\"Anomaly rate: {stl_result.payload['anomaly_rate']:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d93ea0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract anomaly information\n",
    "anomaly_indices = stl_result.payload['anomaly_indices']\n",
    "anomaly_dates = df.loc[anomaly_indices, 'date'].tolist()\n",
    "anomaly_values = df.loc[anomaly_indices, 'gdp'].tolist()\n",
    "\n",
    "print(f\"\\nDetected Anomalies:\")\n",
    "print(\"=\" * 70)\n",
    "for date, value, idx in zip(anomaly_dates, anomaly_values, anomaly_indices):\n",
    "    print(f\"  {date.strftime('%Y-%m-%d')}: GDP = {value:.2f} (index {idx})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25a1ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize STL decomposition\n",
    "decomposition = stl_result.payload['decomposition']\n",
    "\n",
    "fig, axes = plt.subplots(4, 1, figsize=(14, 12))\n",
    "\n",
    "# Original series\n",
    "axes[0].plot(df['date'], df['gdp'], linewidth=2)\n",
    "# Mark anomalies\n",
    "axes[0].scatter(df.loc[anomaly_indices, 'date'], \n",
    "               df.loc[anomaly_indices, 'gdp'],\n",
    "               color='red', s=100, zorder=5, label='Anomaly')\n",
    "axes[0].set_title('Original GDP Series with Detected Anomalies', fontsize=14, fontweight='bold')\n",
    "axes[0].set_ylabel('GDP')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Trend\n",
    "axes[1].plot(df['date'], decomposition['trend'], linewidth=2, color='darkblue')\n",
    "axes[1].set_title('Trend Component', fontsize=14, fontweight='bold')\n",
    "axes[1].set_ylabel('Trend')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Seasonal\n",
    "axes[2].plot(df['date'], decomposition['seasonal'], linewidth=2, color='green')\n",
    "axes[2].set_title('Seasonal Component', fontsize=14, fontweight='bold')\n",
    "axes[2].set_ylabel('Seasonal')\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "# Residual with threshold\n",
    "residual = decomposition['residual']\n",
    "threshold = stl_result.payload['threshold_value']\n",
    "axes[3].plot(df['date'], residual, linewidth=1.5, color='gray', label='Residual')\n",
    "axes[3].axhline(y=threshold, color='red', linestyle='--', linewidth=1.5, label=f'Threshold (+{threshold:.2f})')\n",
    "axes[3].axhline(y=-threshold, color='red', linestyle='--', linewidth=1.5, label=f'Threshold (-{threshold:.2f})')\n",
    "axes[3].scatter(df.loc[anomaly_indices, 'date'], \n",
    "               residual[anomaly_indices],\n",
    "               color='red', s=100, zorder=5, label='Anomaly')\n",
    "axes[3].set_title('Residual Component with Anomaly Threshold', fontsize=14, fontweight='bold')\n",
    "axes[3].set_ylabel('Residual')\n",
    "axes[3].set_xlabel('Date')\n",
    "axes[3].legend()\n",
    "axes[3].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6539b16a",
   "metadata": {},
   "source": [
    "## Model 2: Isolation Forest - Multivariate Anomaly Detection\n",
    "\n",
    "Isolation Forest detects anomalies in multivariate data by isolating observations.\n",
    "\n",
    "**Key Concept:** Anomalies are easier to isolate (require fewer splits in a tree) than normal points.\n",
    "\n",
    "**Advantages:**\n",
    "- Works with multiple features\n",
    "- No assumptions about data distribution\n",
    "- Efficient for large datasets\n",
    "- Handles high-dimensional data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebbbcd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare multivariate data\n",
    "# Load employment data with multiple features\n",
    "employment_df = pd.read_csv('../data/employment_sample.csv')\n",
    "employment_df['date'] = pd.to_datetime(employment_df['date'])\n",
    "\n",
    "print(f\"Employment dataset shape: {employment_df.shape}\")\n",
    "print(f\"Features: {employment_df.columns.tolist()}\")\n",
    "employment_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ece1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the multivariate data\n",
    "fig, axes = plt.subplots(3, 1, figsize=(14, 10))\n",
    "\n",
    "sectors = ['manufacturing', 'services', 'technology']\n",
    "colors = ['steelblue', 'green', 'orange']\n",
    "\n",
    "for ax, sector, color in zip(axes, sectors, colors):\n",
    "    ax.plot(employment_df['date'], employment_df[sector], linewidth=2, color=color)\n",
    "    ax.set_title(f'{sector.capitalize()} Employment', fontsize=14, fontweight='bold')\n",
    "    ax.set_ylabel('Employment')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "axes[-1].set_xlabel('Date')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bab8a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure Isolation Forest model\n",
    "if_params = {\n",
    "    'feature_cols': ['manufacturing', 'services', 'technology', 'construction', 'retail'],\n",
    "    'contamination': 0.05,  # Expected proportion of anomalies (5%)\n",
    "    'n_estimators': 100,    # Number of trees\n",
    "    'max_samples': 'auto',  # Samples per tree\n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "meta_if = ModelMeta(\n",
    "    name=\"Employment_IsolationForest\",\n",
    "    version=\"1.0\",\n",
    "    author=\"Tutorial\",\n",
    "    description=\"Isolation Forest for multivariate employment anomalies\"\n",
    ")\n",
    "\n",
    "# Fit Isolation Forest\n",
    "if_model = IsolationForestAnomalyModel(if_params, meta_if)\n",
    "if_result = if_model.fit(employment_df)\n",
    "\n",
    "print(\"Isolation Forest anomaly detection completed!\")\n",
    "print(f\"\\nNumber of anomalies detected: {if_result.payload['n_anomalies']}\")\n",
    "print(f\"Anomaly rate: {if_result.payload['anomaly_rate']:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f363d31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract anomaly information\n",
    "if_anomaly_indices = if_result.payload['anomaly_indices']\n",
    "if_anomaly_scores = if_result.payload['anomaly_scores']\n",
    "\n",
    "# Create dataframe with anomalies\n",
    "anomaly_df = employment_df.loc[if_anomaly_indices].copy()\n",
    "anomaly_df['anomaly_score'] = [if_anomaly_scores[i] for i in if_anomaly_indices]\n",
    "anomaly_df = anomaly_df.sort_values('anomaly_score')\n",
    "\n",
    "print(\"\\nTop 10 Anomalies (Most Extreme):\")\n",
    "print(\"=\" * 100)\n",
    "print(anomaly_df[['date', 'manufacturing', 'services', 'technology', 'anomaly_score']].head(10).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6e1a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize anomalies in multivariate space\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# 2D projections\n",
    "feature_pairs = [\n",
    "    ('manufacturing', 'services'),\n",
    "    ('manufacturing', 'technology'),\n",
    "    ('services', 'technology'),\n",
    "    ('construction', 'retail')\n",
    "]\n",
    "\n",
    "for ax, (feat1, feat2) in zip(axes.flat, feature_pairs):\n",
    "    # Plot normal points\n",
    "    normal_mask = ~employment_df.index.isin(if_anomaly_indices)\n",
    "    ax.scatter(employment_df.loc[normal_mask, feat1], \n",
    "              employment_df.loc[normal_mask, feat2],\n",
    "              alpha=0.5, s=30, label='Normal', color='blue')\n",
    "    \n",
    "    # Plot anomalies\n",
    "    ax.scatter(employment_df.loc[if_anomaly_indices, feat1],\n",
    "              employment_df.loc[if_anomaly_indices, feat2],\n",
    "              alpha=0.8, s=100, label='Anomaly', color='red', edgecolor='black')\n",
    "    \n",
    "    ax.set_xlabel(feat1.capitalize())\n",
    "    ax.set_ylabel(feat2.capitalize())\n",
    "    ax.set_title(f'{feat1.capitalize()} vs {feat2.capitalize()}', fontsize=12, fontweight='bold')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('Multivariate Anomaly Detection - 2D Projections', fontsize=16, fontweight='bold', y=1.0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f520e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time series view of anomalies\n",
    "fig, axes = plt.subplots(3, 1, figsize=(14, 10))\n",
    "\n",
    "sectors_plot = ['manufacturing', 'services', 'technology']\n",
    "colors_plot = ['steelblue', 'green', 'orange']\n",
    "\n",
    "for ax, sector, color in zip(axes, sectors_plot, colors_plot):\n",
    "    # Plot time series\n",
    "    ax.plot(employment_df['date'], employment_df[sector], linewidth=2, color=color, alpha=0.7)\n",
    "    \n",
    "    # Mark anomalies\n",
    "    ax.scatter(employment_df.loc[if_anomaly_indices, 'date'],\n",
    "              employment_df.loc[if_anomaly_indices, sector],\n",
    "              color='red', s=100, zorder=5, edgecolor='black', linewidth=1.5, label='Anomaly')\n",
    "    \n",
    "    ax.set_title(f'{sector.capitalize()} Employment with Anomalies', fontsize=14, fontweight='bold')\n",
    "    ax.set_ylabel('Employment')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "axes[-1].set_xlabel('Date')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9bea5e",
   "metadata": {},
   "source": [
    "## Feature Importance for Anomaly Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076ffe99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importance (if available)\n",
    "if 'feature_importance' in if_result.payload:\n",
    "    importance_df = if_result.payload['feature_importance']\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(importance_df['feature'], importance_df['importance'], color='steelblue', edgecolor='black')\n",
    "    plt.xlabel('Importance Score')\n",
    "    plt.title('Feature Importance for Anomaly Detection', fontsize=16, fontweight='bold')\n",
    "    plt.grid(True, alpha=0.3, axis='x')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nFeature Importance:\")\n",
    "    print(importance_df.to_string(index=False))\n",
    "else:\n",
    "    print(\"Feature importance not available from model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ed1962",
   "metadata": {},
   "source": [
    "## Comparing STL vs Isolation Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca7c26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Method Comparison:\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nSTL Anomaly Detection:\")\n",
    "print(f\"  - Univariate (single time series)\")\n",
    "print(f\"  - Detects deviations from seasonal pattern\")\n",
    "print(f\"  - Interpretable (can see trend, seasonal, residual)\")\n",
    "print(f\"  - Threshold-based (e.g., 3 standard deviations)\")\n",
    "print(f\"  - Best for: Regular seasonal data, clear patterns\")\n",
    "print(f\"  - Detected: {stl_result.payload['n_anomalies']} anomalies\")\n",
    "\n",
    "print(\"\\nIsolation Forest:\")\n",
    "print(f\"  - Multivariate (multiple features)\")\n",
    "print(f\"  - Detects unusual combinations of values\")\n",
    "print(f\"  - Machine learning-based (no distribution assumptions)\")\n",
    "print(f\"  - Contamination parameter (expected anomaly rate)\")\n",
    "print(f\"  - Best for: Complex relationships, high dimensions\")\n",
    "print(f\"  - Detected: {if_result.payload['n_anomalies']} anomalies\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4da56df",
   "metadata": {},
   "source": [
    "## Practical Applications\n",
    "\n",
    "### 1. Economic Shock Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba932a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use STL to identify economic shocks in GDP\n",
    "print(\"Potential Economic Shocks Detected:\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "if len(anomaly_dates) > 0:\n",
    "    for date, value in zip(anomaly_dates, anomaly_values):\n",
    "        pct_change = ((value - df['gdp'].mean()) / df['gdp'].mean()) * 100\n",
    "        shock_type = \"Positive\" if pct_change > 0 else \"Negative\"\n",
    "        print(f\"\\n{date.strftime('%Y Q%q')}: {shock_type} shock\")\n",
    "        print(f\"  GDP: {value:.2f} ({pct_change:+.1f}% from mean)\")\n",
    "        print(f\"  Possible causes: Policy change, external shock, data error\")\n",
    "else:\n",
    "    print(\"\\nNo significant economic shocks detected in this period\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c068ed",
   "metadata": {},
   "source": [
    "### 2. Business Process Monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4125b07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Isolation Forest for business monitoring\n",
    "print(\"Employment Anomalies - Action Items:\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for idx in if_anomaly_indices[:5]:  # Show top 5\n",
    "    row = employment_df.loc[idx]\n",
    "    score = if_anomaly_scores[idx]\n",
    "    \n",
    "    print(f\"\\n{row['date'].strftime('%Y-%m-%d')} (Score: {score:.3f}):\")\n",
    "    \n",
    "    # Identify which sectors are unusual\n",
    "    for sector in ['manufacturing', 'services', 'technology']:\n",
    "        sector_mean = employment_df[sector].mean()\n",
    "        sector_std = employment_df[sector].std()\n",
    "        z_score = (row[sector] - sector_mean) / sector_std\n",
    "        \n",
    "        if abs(z_score) > 2:\n",
    "            print(f\"  - {sector.capitalize()}: {row[sector]:.0f} ({z_score:+.1f} std devs)\")\n",
    "    \n",
    "    print(f\"  Action: Investigate data quality, verify hiring/layoff events\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821574f5",
   "metadata": {},
   "source": [
    "### 3. Threshold Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f79c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different threshold values for STL\n",
    "thresholds = [2.0, 2.5, 3.0, 3.5]\n",
    "results = []\n",
    "\n",
    "for thresh in thresholds:\n",
    "    params = stl_params.copy()\n",
    "    params['threshold'] = thresh\n",
    "    \n",
    "    model = STLAnomalyModel(params, meta_stl)\n",
    "    result = model.fit(df)\n",
    "    \n",
    "    results.append({\n",
    "        'threshold': thresh,\n",
    "        'n_anomalies': result.payload['n_anomalies'],\n",
    "        'anomaly_rate': result.payload['anomaly_rate']\n",
    "    })\n",
    "\n",
    "# Plot threshold sensitivity\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nThreshold Sensitivity Analysis:\")\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(results_df['threshold'], results_df['n_anomalies'], \n",
    "         marker='o', markersize=8, linewidth=2, color='steelblue')\n",
    "plt.xlabel('Threshold (Standard Deviations)')\n",
    "plt.ylabel('Number of Anomalies Detected')\n",
    "plt.title('STL Anomaly Detection: Threshold Sensitivity', fontsize=16, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nGuidelines:\")\n",
    "print(\"  - Threshold 2.0: More sensitive (more anomalies, some false positives)\")\n",
    "print(\"  - Threshold 3.0: Balanced (standard choice)\")\n",
    "print(\"  - Threshold 3.5: Conservative (fewer anomalies, high confidence)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db4b23c",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "1. **STL Anomaly Detection:**\n",
    "   - Best for univariate time series with seasonality\n",
    "   - Decomposes into trend, seasonal, residual\n",
    "   - Anomalies = large residuals (beyond threshold)\n",
    "   - Interpretable and visual\n",
    "   - Threshold typically 2-3 standard deviations\n",
    "\n",
    "2. **Isolation Forest:**\n",
    "   - Best for multivariate data\n",
    "   - No assumptions about data distribution\n",
    "   - Detects unusual combinations of features\n",
    "   - Contamination parameter sets expected anomaly rate\n",
    "   - Scalable to high dimensions\n",
    "\n",
    "3. **Model Selection:**\n",
    "   - Use **STL** when: Single time series, clear seasonality, need interpretability\n",
    "   - Use **Isolation Forest** when: Multiple features, complex patterns, no clear structure\n",
    "\n",
    "4. **Applications:**\n",
    "   - Economic shock detection (GDP, employment)\n",
    "   - Fraud detection (transactions, claims)\n",
    "   - System monitoring (servers, sensors)\n",
    "   - Quality control (manufacturing, processes)\n",
    "   - Revenue anomaly detection (sales, subscriptions)\n",
    "\n",
    "5. **Best Practices:**\n",
    "   - Tune threshold/contamination based on domain knowledge\n",
    "   - Validate anomalies (not all anomalies are errors)\n",
    "   - Combine with domain expertise\n",
    "   - Monitor false positive/negative rates\n",
    "   - Update models as patterns change\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- Implement real-time anomaly detection\n",
    "- Combine STL and Isolation Forest for hybrid detection\n",
    "- Add anomaly classification (shock types)\n",
    "- Integrate with alerting systems\n",
    "- Perform root cause analysis on detected anomalies\n",
    "- Build anomaly explanation tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8019b4ee",
   "metadata": {},
   "source": [
    "## Export Results & Reproducibility\n",
    "\n",
    "This section exports detection results and metadata for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666c84de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "# Create output directory\n",
    "output_dir = Path('../outputs') / f'anomaly_detection_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}'\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Exporting results to: {output_dir}\\n\")\n",
    "\n",
    "# Export detection results\n",
    "results_df = pd.DataFrame({\n",
    "    'date': df['date'],\n",
    "    'revenue': df['revenue'],\n",
    "    'actual_anomaly': df['is_anomaly'],\n",
    "    'stl_detected': stl_anomalies,\n",
    "    'iforest_detected': iforest_anomalies,\n",
    "    'combined_detected': combined_anomalies\n",
    "})\n",
    "results_df.to_csv(output_dir / 'anomaly_detection_results.csv', index=False)\n",
    "print(\" Exported detection results\")\n",
    "\n",
    "# Export performance metrics\n",
    "metrics_df = pd.DataFrame({\n",
    "    'Method': ['STL', 'Isolation Forest', 'Combined'],\n",
    "    'Precision': [stl_precision, iforest_precision, combined_precision],\n",
    "    'Recall': [stl_recall, iforest_recall, combined_recall],\n",
    "    'F1-Score': [stl_f1, iforest_f1, combined_f1]\n",
    "})\n",
    "metrics_df.to_csv(output_dir / 'detection_metrics.csv', index=False)\n",
    "print(\" Exported performance metrics\")\n",
    "\n",
    "# Export metadata\n",
    "metadata = {\n",
    "    \"tutorial\": \"05_anomaly_detection.ipynb\",\n",
    "    \"version\": \"v1.0\",\n",
    "    \"execution_date\": datetime.now().isoformat(),\n",
    "    \"models\": [\"STL\", \"Isolation Forest\", \"Combined\"],\n",
    "    \"dataset\": {\n",
    "        \"name\": \"revenue_anomaly_sample.csv\",\n",
    "        \"records\": len(df),\n",
    "        \"anomalies_injected\": df['is_anomaly'].sum(),\n",
    "        \"anomaly_rate\": f\"{(df['is_anomaly'].sum() / len(df) * 100):.2f}%\"\n",
    "    },\n",
    "    \"reproducibility\": {\n",
    "        \"random_seed\": 42,\n",
    "        \"python_version\": \"3.9+\",\n",
    "        \"required_packages\": [\"krl-model-zoo\", \"pandas\", \"numpy\", \"matplotlib\", \"statsmodels\", \"scikit-learn\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(output_dir / 'execution_metadata.json', 'w') as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "print(\" Exported execution metadata\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"EXPORT COMPLETE\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d89202d",
   "metadata": {},
   "source": [
    "## Responsible Use & Limitations\n",
    "\n",
    "### Ethical Considerations\n",
    "\n",
    "1. **Data Privacy:**\n",
    "   - This analysis uses synthetic revenue data for demonstration\n",
    "   - Real applications must protect sensitive business data\n",
    "   - Ensure compliance with data protection regulations (GDPR, CCPA)\n",
    "   - Obtain proper authorization before analyzing confidential data\n",
    "\n",
    "2. **Bias & Fairness:**\n",
    "   - Anomaly detection may flag legitimate unusual behavior\n",
    "   - Avoid automatic decision-making without human review\n",
    "   - Consider context and business knowledge when interpreting anomalies\n",
    "   - False positives can cause unnecessary investigations and costs\n",
    "\n",
    "3. **Limitations:**\n",
    "   - Synthetic data with known anomalies for demonstration only\n",
    "   - Real anomaly detection requires domain expertise and validation\n",
    "   - STL requires sufficient data for seasonal decomposition (2+ cycles)\n",
    "   - Isolation Forest sensitive to contamination parameter\n",
    "   - No single method works best for all types of anomalies\n",
    "   - Concept drift may require model retraining\n",
    "\n",
    "4. **Recommended Use Cases:**\n",
    "   -  Educational purposes and learning\n",
    "   -  Fraud detection with human review\n",
    "   -  Quality control and process monitoring\n",
    "   -  System health monitoring and alerting\n",
    "   -  Automated disciplinary actions without investigation\n",
    "   -  High-stakes decisions without expert validation\n",
    "   -  Real-time critical systems without extensive testing\n",
    "\n",
    "5. **Model Assumptions:**\n",
    "   - STL assumes stable trend and seasonal patterns\n",
    "   - Isolation Forest assumes anomalies are rare (< 10%)\n",
    "   - Both methods require appropriate thresholds/contamination rates\n",
    "   - Ground truth labels needed for performance evaluation\n",
    "\n",
    "### Best Practices\n",
    "\n",
    "- Always validate detection results with domain experts\n",
    "- Use multiple detection methods for robustness\n",
    "- Tune thresholds based on business costs (false positives vs. false negatives)\n",
    "- Regularly update models with new data and feedback\n",
    "- Implement human-in-the-loop review for flagged anomalies\n",
    "- Monitor detection performance over time\n",
    "- Document investigation outcomes to improve models\n",
    "- Consider seasonal and business context in interpretation\n",
    "\n",
    "For questions about responsible use: info@krlabs.dev"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0585134",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "1. **Cleveland, R. B., Cleveland, W. S., McRae, J. E., & Terpenning, I.** (1990). STL: A seasonal-trend decomposition procedure based on loess. *Journal of Official Statistics*, 6(1), 3-73.\n",
    "\n",
    "2. **Liu, F. T., Ting, K. M., & Zhou, Z. H.** (2008). Isolation forest. In *2008 Eighth IEEE International Conference on Data Mining* (pp. 413-422). IEEE.\n",
    "\n",
    "3. **Chandola, V., Banerjee, A., & Kumar, V.** (2009). Anomaly detection: A survey. *ACM Computing Surveys*, 41(3), 1-58.\n",
    "\n",
    "4. **Hodge, V., & Austin, J.** (2004). A survey of outlier detection methodologies. *Artificial Intelligence Review*, 22(2), 85-126.\n",
    "\n",
    "5. **Aggarwal, C. C.** (2017). *Outlier Analysis* (2nd ed.). Springer.\n",
    "\n",
    "6. **Hyndman, R. J., & Athanasopoulos, G.** (2021). *Forecasting: Principles and Practice* (3rd ed.). OTexts. https://otexts.com/fpp3/\n",
    "\n",
    "---\n",
    "\n",
    "## Citation\n",
    "\n",
    "To cite this tutorial:\n",
    "\n",
    "```bibtex\n",
    "@misc{krl_anomaly_detection_2025,\n",
    "  title = {Tutorial 5: Anomaly Detection with STL and Isolation Forest},\n",
    "  author = {KRL Model Zoo Team},\n",
    "  year = {2025},\n",
    "  publisher = {KR-Labs},\n",
    "  url = {https://github.com/KR-Labs/krl-model-zoo},\n",
    "  note = {Tutorial from KRL Model Zoo v1.0.0}\n",
    "}\n",
    "```\n",
    "\n",
    "To cite KRL Model Zoo:\n",
    "\n",
    "```bibtex\n",
    "@software{krl_model_zoo_2025,\n",
    "  title = {KRL Model Zoo: Production-Grade Models for Socioeconomic Analysis},\n",
    "  author = {KR-Labs},\n",
    "  year = {2025},\n",
    "  url = {https://github.com/KR-Labs/krl-model-zoo},\n",
    "  version = {1.0.0},\n",
    "  license = {Apache-2.0}\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa61464",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<div style=\"text-align: center; padding: 20px 0; border-top: 2px solid #333; margin-top: 40px;\">\n",
    "  <p style=\"font-size: 14px; font-weight: bold; margin-bottom: 5px;\">\n",
    "    KR-Labs | Data-Driven Economic Analysis\n",
    "  </p>\n",
    "  <p style=\"font-size: 12px; color: #666; margin: 5px 0;\">\n",
    "    Contact: <a href=\"mailto:info@krlabs.dev\">info@krlabs.dev</a>\n",
    "  </p>\n",
    "  <p style=\"font-size: 11px; color: #666; margin: 5px 0;\">\n",
    "    © 2025 KR-Labs. All rights reserved.<br>\n",
    "    <strong>KR-Labs™</strong> is a trademark of Quipu Research Labs, LLC, a subsidiary of Sudiata Giddasira, Inc.\n",
    "  </p>\n",
    "  <p style=\"font-size: 11px; color: #666; margin: 5px 0;\">\n",
    "    <a href=\"https://www.apache.org/licenses/LICENSE-2.0\" target=\"_blank\">Apache 2.0 License</a> | \n",
    "    <a href=\"https://github.com/KR-Labs/krl-model-zoo\" target=\"_blank\">GitHub Repository</a>\n",
    "  </p>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}